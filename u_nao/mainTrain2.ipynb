{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding to square \n",
    "def pad_to_square(image):\n",
    "    width, height = image.size\n",
    "    max_wh = max(width, height)\n",
    "    padding = [\n",
    "        (max_wh - width) // 2,      # Left\n",
    "        (max_wh - height) // 2,     # Top\n",
    "        (max_wh - width + 1) // 2,  # Right\n",
    "        (max_wh - height + 1) // 2  # Bottom\n",
    "    ]\n",
    "    return F.pad(image, padding, fill=0)\n",
    "def bounding_box(image):\n",
    "    gray_image = image.convert(\"L\")\n",
    "    binary_image = gray_image.point(lambda p: p > 0 and 255)\n",
    "    bbox = binary_image.getbbox()\n",
    "    return bbox\n",
    "def crop_to_square(image):\n",
    "    bbox = bounding_box(image)\n",
    "    if bbox:\n",
    "        left,top,right,bottom = bbox\n",
    "        width, height = right - left, bottom - top\n",
    "        max_size = max(width, height)\n",
    "        new_left = left - (max_size - width) // 2\n",
    "        new_top = top - (max_size - height) // 2\n",
    "        new_right = new_left + max_size\n",
    "        new_bottom = new_top + max_size\n",
    "        return image.crop((new_left, new_top, new_right, new_bottom))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: pad_to_square(img)),\n",
    "    transforms.Lambda(lambda img: crop_to_square(img)),\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),  # Đảm bảo có dấu ngoặc đơn\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(root='./Datasets', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no': 0, 'yes': 1}\n"
     ]
    }
   ],
   "source": [
    "print(dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.6*len(dataset))\n",
    "test_size = int(len(dataset)*0.2)\n",
    "val_size = len(dataset) - test_size - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "data_train, data_test, data_val = random_split(dataset, [train_size,test_size,val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(data_train, batch_size=32, shuffle=True)\n",
    "test_loader =  DataLoader(data_test, batch_size=32, shuffle=False)\n",
    "val_loader =  DataLoader(data_val, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim  as optim\n",
    "import torch.nn.functional as f\n",
    "# tính kích thước đầu ra:(Input Size−Kernel Size+2*padding)/S + 1\n",
    "# (inputsize- kernel size)/s+1\n",
    "#xây dựng mô hình CNN\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        # Conv2D layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # MaxPooling layers\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        def get_output_size(input_size):\n",
    "            size = input_size\n",
    "            size = (size - 3 + 2 * 1) // 1 + 1  # Conv layer\n",
    "            size = (size - 2) // 2 + 1  # MaxPooling layer\n",
    "            size = (size - 3 + 2 * 1) // 1 + 1  # Conv layer\n",
    "            size = (size - 2) // 2 + 1  # MaxPooling layer\n",
    "            size = (size - 3 + 2 * 1) // 1 + 1  # Conv layer\n",
    "            size = (size - 2) // 2 + 1  # MaxPooling layer\n",
    "            return size\n",
    "\n",
    "        input_size = 64\n",
    "        output_size = get_output_size(input_size)\n",
    "        self.fc1 = nn.Linear(64 * output_size * output_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(f.relu(self.conv1(x)))\n",
    "        x = self.pool(f.relu(self.conv2(x)))\n",
    "        x = self.pool(f.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = f.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)  # Remove sigmoid here\n",
    "        return x\n",
    "model = CNNModel()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(predictions, labels):\n",
    "    predictions = torch.sigmoid(predictions)  # Convert logits to probabilities\n",
    "    predicted_classes = (predictions > 0.5).float()  # Convert probabilities to class labels\n",
    "    correct = (predicted_classes == labels).sum().item()\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "train_accuracies =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation dataset: 64.00%\n",
      "Accuracy on validation dataset: 79.83%\n",
      "Accuracy on validation dataset: 82.50%\n",
      "Accuracy on validation dataset: 88.17%\n",
      "Accuracy on validation dataset: 93.67%\n",
      "Accuracy on validation dataset: 88.67%\n",
      "Accuracy on validation dataset: 95.17%\n",
      "Accuracy on validation dataset: 95.33%\n",
      "Accuracy on validation dataset: 93.50%\n",
      "Accuracy on validation dataset: 96.83%\n",
      "Accuracy on validation dataset: 95.17%\n",
      "Accuracy on validation dataset: 97.17%\n",
      "Accuracy on validation dataset: 97.67%\n",
      "Accuracy on validation dataset: 97.33%\n",
      "Accuracy on validation dataset: 96.50%\n",
      "Accuracy on validation dataset: 97.83%\n",
      "Accuracy on validation dataset: 95.33%\n",
      "Accuracy on validation dataset: 97.50%\n",
      "Accuracy on validation dataset: 98.17%\n",
      "Accuracy on validation dataset: 98.17%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "        optimizer.zero_grad()  # xóa gradient cũ\n",
    "        \n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        correct_train += calculate_accuracy(outputs,labels)\n",
    "        labels = labels.unsqueeze(1).float()  # Ensure labels have the correct shape and type\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:  # Print every 2000 batches\n",
    "            print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracy = correct_train / len(train_loader)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.unsqueeze(1).float()\n",
    "            correct_in = calculate_accuracy(outputs, labels)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            correct += (correct_in)  # Accumulate accuracy\n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    accuracy_percentage = (correct*100 / total) if total > 0 else 0\n",
    "    val_accuracies.append(accuracy_percentage/100)\n",
    "    print(f'Accuracy on validation dataset: {accuracy_percentage:.2f}%')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, 'BrainTumorbyTorch.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,21),train_losses)\n",
    "plt.plot(range(1, 21), val_losses, label='Val Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
